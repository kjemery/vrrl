{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do:\n",
    "\n",
    "1. create single symmetrical co-occurrence matrix (with general semantic embeddings)\n",
    "2. determine target/landmark pairings from this matrix \n",
    "3. visualize object clusters\n",
    "4. compare clusters across language models\n",
    "5. design room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import fastparquet\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1168.7/1168.7MB downloaded\n"
     ]
    }
   ],
   "source": [
    "model = api.load('conceptnet-numberbatch-17-06-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read conceptnet\n",
    "conceptnet = pd.read_parquet('conceptnet_small.parquet.gzip',columns=['uri','relation','start_node','end_node','info'])\n",
    "\n",
    "# choose room for which to search relations\n",
    "room =  'kitchen'\n",
    "cn_room = '/c/en/' + room\n",
    "node = 'end_node'\n",
    "object_relations = conceptnet[conceptnet[node] == cn_room]\n",
    "\n",
    "# create list of objects typically associated with chosen room type\n",
    "objs = []\n",
    "\n",
    "for i in range(object_relations.shape[0]):\n",
    "    objs.append(object_relations['start_node'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize object list\n",
    "all_objs = pd.read_excel('post_objects.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create cooccurrence matrix \n",
    "cooccur_target = {} \n",
    "\n",
    "for i in range(len(landmark)):\n",
    "    \n",
    "    selected_targets = list(pair['target'][pair['landmark']==landmarks[i]])\n",
    "    cooccur = np.zeros((len(selected_targets),len(selected_targets)))\n",
    "    \n",
    "    inputs = tokenizer(target, return_tensors=\"np\")\n",
    "    idx_selected_targets = []\n",
    "\n",
    "    for x in range(len(selected_targets)):\n",
    "        idx_selected_targets.append(inputs.input_ids[x][1])\n",
    "\n",
    "    for j in range(len(selected_targets)):\n",
    "    \n",
    "        sentence = 'The [MASK] should be in the ' + room + ' next to the ' + selected_targets[j] + ' on the ' + landmark[i] + '.'\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors=\"tf\")\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "        mask_token_index = tf.where((inputs.input_ids == tokenizer.mask_token_id)[0])\n",
    "        selected_logits = tf.gather_nd(logits[0], indices=mask_token_index)\n",
    "\n",
    "        cooccur[j,:] = tf.nn.softmax(selected_logits.numpy()[0,idx_selected_targets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster corrrelation matrix and visualize\n",
    "cooccur = np.zeros((len(landmark),len(target)))\n",
    "\n",
    "for i in range(len(landmark)):\n",
    "    for j in range(len(target)):\n",
    "        sentence = 'The [MASK] is on the ' + landmark[i] + ' in the ' + room + '.'\n",
    "        result = unmasker(sentence, targets = target[j])\n",
    "        cooccur[i,j] = result[0].get(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 2, 15, 13, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "# determine target landmark pairings\n",
    "num_targets = []\n",
    "\n",
    "for i in range(len(landmarks)):\n",
    "    num_targets.append(sum(pair.landmark == landmarks[i]))\n",
    "    \n",
    "print(num_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11          crab\n",
       "15           fan\n",
       "23    ingredient\n",
       "24          iron\n",
       "25        kettle\n",
       "27         maker\n",
       "33           oil\n",
       "36           pan\n",
       "42           pot\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair['target'][pair['landmark']==landmarks[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    counter\n",
       "1      floor\n",
       "2      table\n",
       "3      shelf\n",
       "4       wall\n",
       "5      stove\n",
       "Name: landmark, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# design room"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2714f9b14993ab0e17bafbebc8c2d5d25362cf93e493fb6a60f0ac0c1d2d5236"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
