{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do:\n",
    "\n",
    "1. create single symmetrical co-occurrence matrix (with general semantic embeddings)\n",
    "2. determine target/landmark pairings from this matrix \n",
    "3. visualize object clusters\n",
    "4. compare clusters across language models\n",
    "5. design room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import fastparquet\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertModel, TFBertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read conceptnet\n",
    "conceptnet = pd.read_parquet('conceptnet_small.parquet.gzip',columns=['uri','relation','start_node','end_node','info'])\n",
    "\n",
    "# choose room for which to search relations\n",
    "room =  'kitchen'\n",
    "cn_room = '/c/en/' + room\n",
    "node = 'end_node'\n",
    "object_relations = conceptnet[conceptnet[node] == cn_room]\n",
    "\n",
    "# create list of objects typically associated with chosen room type\n",
    "objs = []\n",
    "\n",
    "for i in range(object_relations.shape[0]):\n",
    "    objs.append(object_relations['start_node'].iloc[i][6:])\n",
    "\n",
    "## object list pre-processing for use with bert (because bert would tokenize phrases into single words and sometimes words into syllables, i chose the following preprocessing steps)\n",
    "\n",
    "# use second word in word pairing\n",
    "objects = []\n",
    "\n",
    "for i in range(len(objs)):\n",
    "    tmp = str(objs[i]).split('_')\n",
    "    objects.append(tmp[len(tmp)-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get objects (see post_objects.xlsx for more preprocessing info)\n",
    "all_objs = pd.read_excel('post_objects.xlsx')\n",
    "landmarks = all_objs['landmark'].iloc[0:6]\n",
    "objects = all_objs['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load bert\n",
    "mlm = \"bert-base-uncased\"\n",
    "model = TFBertForMaskedLM.from_pretrained(mlm)\n",
    "unmasker = pipeline('fill-mask', model = mlm)\n",
    "\n",
    "# tokenize objects for bert\n",
    "tokenizer = BertTokenizer.from_pretrained(mlm)\n",
    "\n",
    "landmark = []\n",
    "\n",
    "for i in range(len(landmarks)):\n",
    "    new = tokenizer.tokenize(landmarks[i])\n",
    "    \n",
    "    if len(new[0]) == len(landmarks[i]):\n",
    "        landmark.append(new[0])\n",
    "        \n",
    "target = []\n",
    "\n",
    "for i in range(len(objects)):\n",
    "    new = tokenizer.tokenize(objects[i])\n",
    "    \n",
    "    if len(new[0]) == len(objects[i]):\n",
    "        target.append(new[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find indeces of vocab list for targets and landmarks\n",
    "inputs = tokenizer(landmark, return_tensors=\"np\")\n",
    "idx_landmark = []\n",
    "\n",
    "for i in range(len(landmark)):\n",
    "    idx_landmark.append(inputs.input_ids[i][1])\n",
    "    \n",
    "inputs = tokenizer(target, return_tensors=\"np\")\n",
    "idx_target = []\n",
    "\n",
    "for i in range(len(target)):\n",
    "    idx_target.append(inputs.input_ids[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21f52d8ff40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find logits of [MASK] for all vocab words\n",
    "cooccur_landmark = np.zeros((len(landmark),len(target)))\n",
    "\n",
    "for i in range(len(landmark)):\n",
    "    \n",
    "    sentence = 'The [MASK] should be in the ' + room + ' on the ' + landmark[i] +  '.'\n",
    "\n",
    "    inputs = tokenizer(sentence, return_tensors=\"tf\")\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "    mask_token_index = tf.where((inputs.input_ids == tokenizer.mask_token_id)[0])\n",
    "    selected_logits = tf.gather_nd(logits[0], indices=mask_token_index)\n",
    "\n",
    "    cooccur_landmark[i,:] = selected_logits.numpy()[0,idx_target]\n",
    "\n",
    "for i in range(len(target)):\n",
    "        \n",
    "    cooccur_landmark[:,i] = (tf.nn.softmax(cooccur_landmark[:,i])).numpy()\n",
    "\n",
    "plt.imshow(cooccur_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize landmark/target object pairs\n",
    "best_landmark = []\n",
    "for i in range(len(target)):\n",
    "    idx = np.flip(np.argsort(cooccur_landmark[:,i]))\n",
    "    best_landmark.append(landmark[idx[0]])\n",
    "    \n",
    "pair = pd.DataFrame(target, columns=['target'])\n",
    "pair.insert(1,\"landmark\",best_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create target/target cooccurrence matrix for each landmark   \n",
    "cooccur_target = {} \n",
    "\n",
    "for i in range(len(landmark)):\n",
    "    \n",
    "    selected_targets = list(pair['target'][pair['landmark']==landmarks[i]])\n",
    "    cooccur = np.zeros((len(selected_targets),len(selected_targets)))\n",
    "    \n",
    "    inputs = tokenizer(target, return_tensors=\"np\")\n",
    "    idx_selected_targets = []\n",
    "\n",
    "    for x in range(len(selected_targets)):\n",
    "        idx_selected_targets.append(inputs.input_ids[x][1])\n",
    "\n",
    "    for j in range(len(selected_targets)):\n",
    "    \n",
    "        sentence = 'The [MASK] should be in the ' + room + ' next to the ' + selected_targets[j] + ' on the ' + landmark[i] + '.'\n",
    "\n",
    "        inputs = tokenizer(sentence, return_tensors=\"tf\")\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "        mask_token_index = tf.where((inputs.input_ids == tokenizer.mask_token_id)[0])\n",
    "        selected_logits = tf.gather_nd(logits[0], indices=mask_token_index)\n",
    "\n",
    "        cooccur[j,:] = tf.nn.softmax(selected_logits.numpy()[0,idx_selected_targets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark/target co-occurrence mat\n",
    "cooccur = np.zeros((len(landmark),len(target)))\n",
    "\n",
    "for i in range(len(landmark)):\n",
    "    for j in range(len(target)):\n",
    "        sentence = 'The [MASK] is on the ' + landmark[i] + ' in the ' + room + '.'\n",
    "        result = unmasker(sentence, targets = target[j])\n",
    "        cooccur[i,j] = result[0].get(\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target/target co-occurrence mat\n",
    "cooccur = np.zeros((len(landmark),len(target)))\n",
    "\n",
    "for i in range(len(landmark)):\n",
    "    for j in range(len(target)):\n",
    "        sentence = 'The [MASK] is on the ' + landmark[i] + ' in the ' + room + '.'\n",
    "        result = unmasker(sentence, targets = target[j])\n",
    "        cooccur[i,j] = result[0].get(\"score\")\n",
    "sentence = 'The [MASK] is next to the ' + target[0] + ' on the ' + landmark[0] + ' in the ' + room + '.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 2, 15, 13, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "num_targets = []\n",
    "\n",
    "for i in range(len(landmarks)):\n",
    "    num_targets.append(sum(pair.landmark == landmarks[i]))\n",
    "    \n",
    "print(num_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11          crab\n",
       "15           fan\n",
       "23    ingredient\n",
       "24          iron\n",
       "25        kettle\n",
       "27         maker\n",
       "33           oil\n",
       "36           pan\n",
       "42           pot\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair['target'][pair['landmark']==landmarks[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    counter\n",
       "1      floor\n",
       "2      table\n",
       "3      shelf\n",
       "4       wall\n",
       "5      stove\n",
       "Name: landmark, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15551a663999590744caa531dd389e739025d6880d4aaffa21e082c6926e2de4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
